{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Library\n",
    "\n",
    "Compiles list of 587 different models total, varying classifier type and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_models(model, param_grid):\n",
    "    print('Building %s models' % str(model).split('.')[-1][:-2]) \n",
    "    \n",
    "    return list(model(**params) for params in ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgb_models():\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200], \n",
    "        'objective': ['binary:logistic'],   \n",
    "        'max_depth': [3,5,7,10], \n",
    "        'colsample_bytree': [0.5, 0.8, 0.9],\n",
    "        'subsample': [0.5, 0.8, 0.9]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return build_models(XGBClassifier, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rf_models():\n",
    "    param_grid = {\n",
    "        'n_estimators' : [20, 50, 100],\n",
    "        'criterion':  ['gini', 'entropy'],\n",
    "        'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "        'max_depth': [3, 5, 10, 20, 25] \n",
    "    }\n",
    "    \n",
    "    return build_models(RandomForestClassifier, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linsvm_models():\n",
    "    Cs = np.logspace(-7, 2, 10)\n",
    "    \n",
    "    param_grid = {\n",
    "        'C': Cs,\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "    }\n",
    "    \n",
    "    return build_models(LinearSVC, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rbfsvm_models():\n",
    "    Cs = np.logspace(-7, 0, 9)\n",
    "    gammas = np.logspace(-6, 2, 9, base=2)\n",
    "    \n",
    "    param_grid = {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': Cs,\n",
    "        'gamma': gammas\n",
    "    }\n",
    "    \n",
    "    models = []\n",
    "    f_select = SelectKBest(f_classif, k=50)\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        models.append(Pipeline([('filter', f_select), ('svc', SVC(**params))]))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dt_models():\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "        'max_depth': [None,1,2,5,10],\n",
    "        'random_state': np.random.randint(100, size=3)\n",
    "    }\n",
    "    \n",
    "    return build_models(DecisionTreeClassifier, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_models():\n",
    "    Cs = np.logspace(-4, 4, 5)\n",
    "    \n",
    "    param_grid = {\n",
    "        'C': Cs\n",
    "    }\n",
    "    \n",
    "    return build_models(LogisticRegression, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def knn_models():\n",
    "    param_grid = {\n",
    "        'n_neighbors': np.linspace(1, 300, num=25, dtype='int')\n",
    "    }\n",
    "    \n",
    "    return build_models(KNeighborsClassifier, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_models():\n",
    "    param_grid = {\n",
    "        'loss': ['log', 'modified_huber'],\n",
    "        'penalty': ['elasticnet'],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'learning_rate': ['constant', 'optimal'],\n",
    "        'l1_ratio': np.linspace(0.0, 1.0, 3),\n",
    "        'eta0': [0.001, 0.01, 0.1]\n",
    "    }\n",
    "    \n",
    "    return build_models(SGDClassifier, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building XGBClassifier models\n",
      "Building RandomForestClassifier models\n",
      "Building LinearSVC models\n",
      "Building DecisionTreeClassifier models\n",
      "Building LogisticRegression models\n",
      "Building KNeighborsClassifier models\n",
      "Building SGDClassifier models\n"
     ]
    }
   ],
   "source": [
    "models_dict = {}\n",
    "models_dict = {\n",
    "    'xgb': xgb_models(),\n",
    "    'rf': rf_models(),\n",
    "    'linsvm': linsvm_models(),\n",
    "    'rbfsvm': rbfsvm_models(),\n",
    "    'dt': dt_models(),\n",
    "    'log': log_models(),\n",
    "    'knn': knn_models(),\n",
    "    'sgd': sgd_models()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils import load_train, load_test, write_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = load_train('data/train_2008.csv', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train all models on a training set\n",
    "\n",
    "We will store all the trained models in a directory so this only needs to be done once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58200, 366), (58200,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for k in models_dict:\n",
    "    i = 0\n",
    "    for m in models_dict[k]:\n",
    "        models.append(('%s_%d' %(k, i), m))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgb_0'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[371][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally attempted a parallelized approach (see ensemble.py), but my computer couldn't take it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started at 371 because I had previously trained models and interrupted process midway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_0 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_1 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_2 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_3 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_4 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_5 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_6 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_7 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_8 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_9 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_10 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_11 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_12 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_13 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_14 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_15 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_16 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_17 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_18 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_19 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_20 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_21 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_22 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_23 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_24 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_25 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_26 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_27 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_28 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_29 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_30 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_31 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_32 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_33 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_34 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_35 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_36 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_37 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_38 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_39 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_40 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_41 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_42 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_43 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_44 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_45 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_46 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_47 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_48 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_49 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_50 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_51 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_52 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_53 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_54 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_55 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_56 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_57 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_58 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_59 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_60 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_61 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_62 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_63 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_64 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_65 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_66 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_67 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_68 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "xgb_69 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5)\n",
      "\n",
      "xgb_70 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
      "\n",
      "xgb_71 - XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.9)\n",
      "\n",
      "sgd_0 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_1 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_2 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_3 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_4 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_5 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_6 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_7 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_8 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_9 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_10 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_11 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_12 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_13 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_14 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_15 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_16 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_17 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_18 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_19 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_20 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_21 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_22 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_23 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_24 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_25 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_26 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_27 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_28 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_29 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_30 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_31 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_32 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_33 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_34 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_35 - SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_36 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_37 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_38 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_39 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_40 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_41 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_42 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_43 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_44 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_45 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_46 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_47 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_48 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_49 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_50 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_51 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_52 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_53 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_54 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_55 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_56 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_57 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_58 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_59 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_60 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_61 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_62 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_63 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_64 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_65 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_66 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_67 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_68 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_69 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_70 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_71 - SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_72 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_73 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_74 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_75 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_76 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_77 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_78 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_79 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_80 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_81 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_82 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_83 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_84 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_85 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_86 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_87 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_88 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_89 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_90 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_91 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_92 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_93 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_94 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_95 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_96 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_97 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_98 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_99 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_100 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_101 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_102 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_103 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_104 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_105 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_106 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_107 - SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_108 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_109 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_110 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_111 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_112 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_113 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_114 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_115 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_116 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_117 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_118 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_119 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.001, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_120 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_121 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_122 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_123 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_124 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_125 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_126 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_127 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_128 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_129 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_130 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_131 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_132 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_133 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_134 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_135 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_136 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_137 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_138 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_139 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=0.5, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n",
      "sgd_140 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_141 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0,\n",
      "       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "\n",
      "sgd_142 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
      "       loss='log', n_iter=5, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "\n",
      "sgd_143 - SGDClassifier(alpha=0.1, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.1, fit_intercept=True, l1_ratio=1.0, learning_rate='optimal',\n",
      "       loss='modified_huber', n_iter=5, n_jobs=1, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, verbose=0,\n",
      "       warm_start=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = 'models/ensemble_models'\n",
    "\n",
    "for model in models[371:]:\n",
    "    model[1].fit(X_train, y_train)\n",
    "\n",
    "    #print '%s - %s\\n' %(model[0], model[1])\n",
    "    joblib.dump(model[1], os.path.join(SAVE_DIR, '%s.pkl'%(model[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Ensemble Classifier\n",
    "Used log probabilities as a metric for scoring the ensemble. Encapsulated everything into a EnsembleClassifier class later (see ensemble.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the trained models from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "list_m = glob.glob(\"models/ensemble_models/*.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [joblib.load(m) for m in list_m]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
